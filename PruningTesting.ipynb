{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q tensorflow-model-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model for MNIST without pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.3057 - accuracy: 0.9140 - val_loss: 0.1311 - val_accuracy: 0.9618\n",
      "Epoch 2/4\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.1247 - accuracy: 0.9640 - val_loss: 0.1053 - val_accuracy: 0.9700\n",
      "Epoch 3/4\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0891 - accuracy: 0.9740 - val_loss: 0.0718 - val_accuracy: 0.9805\n",
      "Epoch 4/4\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0734 - accuracy: 0.9781 - val_loss: 0.0627 - val_accuracy: 0.9828\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " reshape_5 (Reshape)         (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 26, 26, 12)        120       \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 13, 13, 12)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 2028)              0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                20290     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,410\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 and 1.\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Define the model architecture.\n",
    "model = keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Train the digit classification model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "  train_images,\n",
    "  train_labels,\n",
    "  epochs=4,\n",
    "  validation_split=0.1,\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Baseline Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.9793000221252441\n",
      "Saved baseline model to: C:\\Users\\Jchap\\AppData\\Local\\Temp\\tmprlzoj1de.h5\n"
     ]
    }
   ],
   "source": [
    "_, baseline_model_accuracy = model.evaluate(\n",
    "    test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy)\n",
    "\n",
    "_, keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n",
    "print('Saved baseline model to:', keras_file)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tune model with pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " prune_low_magnitude_reshape  (None, 28, 28, 1)        1         \n",
      " _5 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " prune_low_magnitude_conv2d_  (None, 26, 26, 12)       230       \n",
      " 5 (PruneLowMagnitude)                                           \n",
      "                                                                 \n",
      " prune_low_magnitude_max_poo  (None, 13, 13, 12)       1         \n",
      " ling2d_5 (PruneLowMagnitude                                     \n",
      " )                                                               \n",
      "                                                                 \n",
      " prune_low_magnitude_flatten  (None, 2028)             1         \n",
      " _5 (PruneLowMagnitude)                                          \n",
      "                                                                 \n",
      " prune_low_magnitude_dense_5  (None, 10)               40572     \n",
      "  (PruneLowMagnitude)                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 40,805\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 20,395\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "# Compute end step to finish pruning after 2 epochs.\n",
    "batch_size = 128\n",
    "epochs = 4\n",
    "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
    "\n",
    "num_images = train_images.shape[0] * (1 - validation_split)\n",
    "end_step = np.ceil(num_images / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "# Define model for pruning.\n",
    "pruning_params = {\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                               final_sparsity=0.95,\n",
    "                                                               begin_step=0,\n",
    "                                                               end_step=end_step)\n",
    "}\n",
    "\n",
    "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "# `prune_low_magnitude` requires a recompile.\n",
    "model_for_pruning.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model_for_pruning.summary()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tune the model with pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "422/422 [==============================] - 4s 7ms/step - loss: 0.0962 - accuracy: 0.9724 - val_loss: 0.1049 - val_accuracy: 0.9723\n",
      "Epoch 2/4\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.2487 - accuracy: 0.9306 - val_loss: 0.4806 - val_accuracy: 0.9202\n",
      "Epoch 3/4\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.4378 - accuracy: 0.8820 - val_loss: 0.3169 - val_accuracy: 0.9138\n",
      "Epoch 4/4\n",
      "422/422 [==============================] - 3s 6ms/step - loss: 0.3373 - accuracy: 0.8986 - val_loss: 0.2704 - val_accuracy: 0.9222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1662a286950>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir = tempfile.mkdtemp()\n",
    "\n",
    "callbacks = [\n",
    "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
    "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
    "]\n",
    "\n",
    "model_for_pruning.fit(train_images, train_labels,\n",
    "                  batch_size=batch_size, epochs=epochs, validation_split=validation_split,\n",
    "                  callbacks=callbacks)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate model performance against baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline test accuracy: 0.9793000221252441\n",
      "Pruned test accuracy: 0.913100004196167\n"
     ]
    }
   ],
   "source": [
    "_, model_for_pruning_accuracy = model_for_pruning.evaluate(\n",
    "   test_images, test_labels, verbose=0)\n",
    "\n",
    "print('Baseline test accuracy:', baseline_model_accuracy) \n",
    "print('Pruned test accuracy:', model_for_pruning_accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the Compression Begins"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a compressible model for Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned Keras model to: C:\\Users\\Jchap\\AppData\\Local\\Temp\\tmplrl13ycz.h5\n"
     ]
    }
   ],
   "source": [
    "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
    "\n",
    "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
    "tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
    "print('Saved pruned Keras model to:', pruned_keras_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Jchap\\AppData\\Local\\Temp\\tmpf_8f309e\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Jchap\\AppData\\Local\\Temp\\tmpf_8f309e\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned TFLite model to: C:\\Users\\Jchap\\AppData\\Local\\Temp\\tmpyph5r2ra.tflite\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
    "pruned_tflite_model = converter.convert()\n",
    "\n",
    "_, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(pruned_tflite_file, 'wb') as f:\n",
    "  f.write(pruned_tflite_model)\n",
    "\n",
    "print('Saved pruned TFLite model to:', pruned_tflite_file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compress the models using gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gzipped_model_size(file):\n",
    "  # Returns size of gzipped model, in bytes.\n",
    "  import os\n",
    "  import zipfile\n",
    "\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Jchap\\AppData\\Local\\Temp\\tmp7m5b155p\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\Jchap\\AppData\\Local\\Temp\\tmp7m5b155p\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pruned TFLite model to: C:\\Users\\Jchap\\AppData\\Local\\Temp\\tmpsceg2xhy.tflite\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "_, tflite_model_file = tempfile.mkstemp('.tflite')\n",
    "\n",
    "with open(tflite_model_file, 'wb') as f:\n",
    "  f.write(tflite_model)\n",
    "\n",
    "print('Saved pruned TFLite model to:', tflite_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of baseline Keras model: 98928.00 bytes\n",
      "Size of gzipped baseline Keras model: 78253.00 bytes\n",
      "Zipping compression ratio of 1.2642071230495955\n",
      "\n",
      "\n",
      "Size of Keras TFlite model: 84896.00 bytes (1.1652845834903882 times smaller than the baseline)\n",
      "Size of gzipped Keras TFlite model: 12190.00 bytes (6.4194 times smaller than the zipped baseline)\n",
      "Zipping compression ratio of: 6.964397046759639\n",
      "\n",
      "\n",
      "Size of pruned Keras model: 98928.00 bytes (1.0 times smaller than the baseline)\n",
      "Size of gzipped pruned Keras model: 13019.00 bytes (6.0107 times smaller than the zipped baseline)\n",
      "Zipping compression ratio of: 7.598740302634611\n",
      "\n",
      "\n",
      "Size of pruned TFlite model: 84896.00 bytes (1.1652845834903882 times smaller than the baseline)\n",
      "Size of gzipped pruned TFlite model: 12190.00 bytes (6.4194 times smaller than the zipped baseline)\n",
      "Zipping compression ratio of 6.964397046759639\n",
      "\n",
      "\n",
      "Final Complete Compression: 8.115504511894995 times the size of the baseline model\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of baseline Keras model: %.2f bytes\" % (os.path.getsize(keras_file)))\n",
    "print(\"Size of gzipped baseline Keras model: %.2f bytes\" % (get_gzipped_model_size(keras_file)))\n",
    "print(f\"Zipping compression ratio of {(os.path.getsize(keras_file))/(get_gzipped_model_size(keras_file))}\")\n",
    "print()\n",
    "print()\n",
    "print(\"Size of Keras TFlite model: %.2f bytes\" % (os.path.getsize(tflite_model_file)),f\"({(os.path.getsize(keras_file))/(os.path.getsize(tflite_model_file))} times smaller than the baseline)\")\n",
    "print(\"Size of gzipped Keras TFlite model: %.2f bytes\" % (get_gzipped_model_size(tflite_model_file)),f\"({(get_gzipped_model_size(keras_file))/(get_gzipped_model_size(tflite_model_file)):.4f} times smaller than the zipped baseline)\")\n",
    "print(f\"Zipping compression ratio of: {(os.path.getsize(tflite_model_file))/(get_gzipped_model_size(tflite_model_file))}\")\n",
    "print()\n",
    "print()\n",
    "print(\"Size of pruned Keras model: %.2f bytes\" % (os.path.getsize(pruned_keras_file)),f\"({(os.path.getsize(keras_file))/(os.path.getsize(pruned_keras_file))} times smaller than the baseline)\")\n",
    "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(pruned_keras_file)),f\"({(get_gzipped_model_size(keras_file))/(get_gzipped_model_size(pruned_keras_file)):.4f} times smaller than the zipped baseline)\")\n",
    "print(f\"Zipping compression ratio of: {(os.path.getsize(pruned_keras_file))/(get_gzipped_model_size(pruned_keras_file))}\")\n",
    "print()\n",
    "print()\n",
    "print(\"Size of pruned TFlite model: %.2f bytes\" % (os.path.getsize(pruned_tflite_file)),f\"({(os.path.getsize(keras_file))/(os.path.getsize(pruned_tflite_file))} times smaller than the baseline)\")\n",
    "print(\"Size of gzipped pruned TFlite model: %.2f bytes\" % (get_gzipped_model_size(pruned_tflite_file)),f\"({(get_gzipped_model_size(keras_file))/(get_gzipped_model_size(pruned_tflite_file)):.4f} times smaller than the zipped baseline)\")\n",
    "print(f\"Zipping compression ratio of {(os.path.getsize(pruned_tflite_file))/(get_gzipped_model_size(pruned_tflite_file))}\")\n",
    "print()\n",
    "print()\n",
    "print(f\"Final Complete Compression: {os.path.getsize(keras_file)/get_gzipped_model_size(pruned_tflite_file)} times the size of the baseline model\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
